# 锁

## 行锁

MySQL 的行锁是在各个引擎自己实现的。MyISAM 不支持行锁，

InnoDB 的事务中，行锁在需要时加上，等到提交时释放。这个就是两阶段锁协议。
> 因此，在事务中如果要锁多行，要把最可能引起锁冲突、最可能影响并发度的锁往后放。

## 死锁和死锁检测

线程间循环依赖资源，且都在等待对方释放资源，会让几个线程都进入无限等待状态，就是死锁。

> 死锁后的策略
> * 设置等待超时时间，```innodb_lock_wait_time```
> * 发起死锁检测，发现死锁后，主动回滚死锁链条中的某个事务，让其他事务继续执行。将参数 ```innodb_deadlock_detect``` 设置为 on ，表示开启这个逻辑。默认值为 on。

在 InnoDB 中，```innodb_lock_wait_time``` 默认值是 50s ，如果使用第一个策略，出现死锁后，第一个被锁住的线程要等待要等待这么长时间才可以推出，这是无法接受的。

但是我们也不能设置为过短的时间，这会影响正常的锁等待。因此使用第二种策略：死锁检测。

每一个事务被锁是，看他所依赖的线程有没有被锁，如此循环，最后判断是否出现了循环等待，也就是死锁。但是死锁检测比较消耗 CPU 资源。

那么
* 如果判断这个业务一定不会出现死锁，可以临时关闭。但是这是有风险的。对于死锁，检测后的回滚是业务无损的。而关闭检测导致的超时，是业务有损的。
* 控制并发度。在客户端控制，就是很小，但如果客户端很多，也不能降低。因此做在服务端。可以在中间件中控制，或者修改 MySQL 源码。基本思路就是，对于同行的更新，在进入引擎之前排队。这样不会有大量的死锁检测了。
* 如果团队中没有数据库方面的专家，可以从设计方面实现。可以将一行的更新拆分成多行，每次随机选取一行更新。例如将账户余额拆分成多行，总余额等于多行之和，但需要业务上增加判断，防止余额为负数的情况出现。


### 问题

要从表 T 删除前 10000 行数据，以下哪种操作更合理

* 第一种，直接执行 delete from T limit 10000;
* 第二种，在一个连接中循环执行 20 次 delete from T limit 500;
* 第三种，在 20 个连接中同时执行 delete from T limit 500。